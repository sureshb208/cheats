{"cells":[{"cell_type":"markdown","source":["-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5e55d030-3d6f-427e-8eb9-3af1b1515da5"}}},{"cell_type":"markdown","source":["# Spark SQL\n\nDemonstrate fundamental concepts in Spark SQL using the DataFrame API.\n\n##### Objectives\n1. Run a SQL query\n1. Create a DataFrame from a table\n1. Write the same query using DataFrame transformations\n1. Trigger computation with DataFrame actions\n1. Convert between DataFrames and SQL\n\n##### Methods\n- <a href=\"https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html#spark-session-apis\" target=\"_blank\">SparkSession</a>: `sql`, `table`\n- <a href=\"https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.html\" target=\"_blank\">DataFrame</a>:\n  - Transformations:  `select`, `where`, `orderBy`\n  - Actions: `show`, `count`, `take`\n  - Other methods: `printSchema`, `schema`, `createOrReplaceTempView`"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"05a2eac1-e1a0-47c3-a385-4bcf1db54097"}}},{"cell_type":"code","source":["%run ./Includes/Classroom-Setup-SQL"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"105427f2-b864-44a3-a76b-a891c4aa2479"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":[""]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Finished setting up utiltity methods...","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["Finished setting up utiltity methods..."]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Datasets mounted and student environment set up","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["Datasets mounted and student environment set up"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["## Multiple Interfaces\nSpark SQL is a module for structured data processing with multiple interfaces.  \n\nWe can interact with Spark SQL in two ways:\n1. Executing SQL queries\n1. Working with the DataFrame API."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ff88c70b-32d7-45ef-814c-3e47a0a0cd04"}}},{"cell_type":"markdown","source":["**Method 1: Executing SQL queries**  \n\nThis is how we interacted with Spark SQL in the previous lesson."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9e3b1827-2a13-4541-a70b-780879bcfebf"}}},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"aafb24f0-c52e-43f7-9739-0e551ed96010"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%sql\nshow tables"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"88a8dc8a-d24e-4ece-8b80-b41a19508d46"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["dbacademy_digithat123_gmail_com_spark_programming_asp_1_3___spark_sql","events",false],["dbacademy_digithat123_gmail_com_spark_programming_asp_1_3___spark_sql","products",false],["dbacademy_digithat123_gmail_com_spark_programming_asp_1_3___spark_sql","sales",false],["dbacademy_digithat123_gmail_com_spark_programming_asp_1_3___spark_sql","users",false]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"database","type":"\"string\"","metadata":"{}"},{"name":"tableName","type":"\"string\"","metadata":"{}"},{"name":"isTemporary","type":"\"boolean\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>database</th><th>tableName</th><th>isTemporary</th></tr></thead><tbody><tr><td>dbacademy_digithat123_gmail_com_spark_programming_asp_1_3___spark_sql</td><td>events</td><td>false</td></tr><tr><td>dbacademy_digithat123_gmail_com_spark_programming_asp_1_3___spark_sql</td><td>products</td><td>false</td></tr><tr><td>dbacademy_digithat123_gmail_com_spark_programming_asp_1_3___spark_sql</td><td>sales</td><td>false</td></tr><tr><td>dbacademy_digithat123_gmail_com_spark_programming_asp_1_3___spark_sql</td><td>users</td><td>false</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sql\nselect * from products"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"19a086ba-0ea4-4476-b4ea-308b7557da8c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["M_PREM_Q","Premium Queen Mattress",1795.0],["M_STAN_F","Standard Full Mattress",945.0],["M_PREM_F","Premium Full Mattress",1695.0],["M_PREM_T","Premium Twin Mattress",1095.0],["M_PREM_K","Premium King Mattress",1995.0],["P_DOWN_S","Standard Down Pillow",119.0],["M_STAN_Q","Standard Queen Mattress",1045.0],["M_STAN_K","Standard King Mattress",1195.0],["M_STAN_T","Standard Twin Mattress",595.0],["P_FOAM_S","Standard Foam Pillow",59.0],["P_FOAM_K","King Foam Pillow",79.0],["P_DOWN_K","King Down Pillow",159.0]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"item_id","type":"\"string\"","metadata":"{}"},{"name":"name","type":"\"string\"","metadata":"{}"},{"name":"price","type":"\"double\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>item_id</th><th>name</th><th>price</th></tr></thead><tbody><tr><td>M_PREM_Q</td><td>Premium Queen Mattress</td><td>1795.0</td></tr><tr><td>M_STAN_F</td><td>Standard Full Mattress</td><td>945.0</td></tr><tr><td>M_PREM_F</td><td>Premium Full Mattress</td><td>1695.0</td></tr><tr><td>M_PREM_T</td><td>Premium Twin Mattress</td><td>1095.0</td></tr><tr><td>M_PREM_K</td><td>Premium King Mattress</td><td>1995.0</td></tr><tr><td>P_DOWN_S</td><td>Standard Down Pillow</td><td>119.0</td></tr><tr><td>M_STAN_Q</td><td>Standard Queen Mattress</td><td>1045.0</td></tr><tr><td>M_STAN_K</td><td>Standard King Mattress</td><td>1195.0</td></tr><tr><td>M_STAN_T</td><td>Standard Twin Mattress</td><td>595.0</td></tr><tr><td>P_FOAM_S</td><td>Standard Foam Pillow</td><td>59.0</td></tr><tr><td>P_FOAM_K</td><td>King Foam Pillow</td><td>79.0</td></tr><tr><td>P_DOWN_K</td><td>King Down Pillow</td><td>159.0</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sql\nSELECT name, price\nFROM products\nWHERE price < 200\nORDER BY price"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"18010dc8-d877-4d08-b00e-4662cc39de81"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["Standard Foam Pillow",59.0],["King Foam Pillow",79.0],["Standard Down Pillow",119.0],["King Down Pillow",159.0]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":[],"pivotAggregation":null,"xColumns":[],"yColumns":[]},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"name","type":"\"string\"","metadata":"{}"},{"name":"price","type":"\"double\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>name</th><th>price</th></tr></thead><tbody><tr><td>Standard Foam Pillow</td><td>59.0</td></tr><tr><td>King Foam Pillow</td><td>79.0</td></tr><tr><td>Standard Down Pillow</td><td>119.0</td></tr><tr><td>King Down Pillow</td><td>159.0</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["**Method 2: Working with the DataFrame API**\n\nWe can also express Spark SQL queries using the DataFrame API.  \nThe following cell returns a DataFrame containing the same results as those retrieved above."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3e07a7b4-2fec-42a5-89a7-1f0af30a8d0e"}}},{"cell_type":"code","source":["display(spark.table(\"products\")\n  .select(\"name\", \"price\")\n  .where(\"price < 200\")\n  .orderBy(\"price\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e789cbe6-cc32-41bb-a408-564993cd4af2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["Standard Foam Pillow",59.0],["King Foam Pillow",79.0],["Standard Down Pillow",119.0],["King Down Pillow",159.0]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":[],"pivotAggregation":null,"xColumns":[],"yColumns":[]},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"name","type":"\"string\"","metadata":"{}"},{"name":"price","type":"\"double\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>name</th><th>price</th></tr></thead><tbody><tr><td>Standard Foam Pillow</td><td>59.0</td></tr><tr><td>King Foam Pillow</td><td>79.0</td></tr><tr><td>Standard Down Pillow</td><td>119.0</td></tr><tr><td>King Down Pillow</td><td>159.0</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["We'll go over the syntax for the DataFrame API later in the lesson, but you can see this builder design pattern allows us to chain a sequence of operations very similar to those we find in SQL."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5b5d4b65-9bbe-43df-bab4-2e8a40f57253"}}},{"cell_type":"markdown","source":["## Query Execution\nWe can express the same query using any interface. The Spark SQL engine generates the same query plan used to optimize and execute on our Spark cluster.\n\n![query execution engine](https://files.training.databricks.com/images/aspwd/spark_sql_query_execution_engine.png)\n\n<img src=\"https://files.training.databricks.com/images/icon_note_32.png\" alt=\"Note\"> Resilient Distributed Datasets (RDDs) are the low-level representation of datasets processed by a Spark cluster. In early versions of Spark, you had to write <a href=\"https://spark.apache.org/docs/latest/rdd-programming-guide.html\" target=\"_blank\">code manipulating RDDs directly</a>. In modern versions of Spark you should instead use the higher-level DataFrame APIs, which Spark automatically compiles into low-level RDD operations."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bfab5f47-f5d0-4022-86db-340cf8a124cf"}}},{"cell_type":"markdown","source":["## Spark API Documentation\n\nTo learn how we work with DataFrames in Spark SQL, let's first look at the Spark API documentation.  \nThe main Spark [documentation](https://spark.apache.org/docs/latest/) page includes links to API docs and helpful guides for each version of Spark.  \n\nThe [Scala API](https://spark.apache.org/docs/latest/api/scala/org/apache/spark/index.html) and [Python API](https://spark.apache.org/docs/latest/api/python/index.html) are most commonly used, and it's often helpful to reference the documentation for both languages.  \nScala docs tend to be more comprehensive, and Python docs tend to have more code examples.\n\n#### Navigating Docs for the Spark SQL Module\nFind the Spark SQL module by navigating to `org.apache.spark.sql` in the Scala API or `pyspark.sql` in the Python API.  \nThe first class we'll explore in this module is the `SparkSession` class. You can find this by entering \"SparkSession\" in the search bar."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cdc8016a-be57-405e-af21-b8234534a987"}}},{"cell_type":"markdown","source":["## SparkSession\nThe `SparkSession` class is the single entry point to all functionality in Spark using the DataFrame API. \n\nIn Databricks notebooks, the SparkSession is created for you, stored in a variable called `spark`."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6d1a125e-da84-4e29-8a7e-0131c756702c"}}},{"cell_type":"code","source":["spark"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"19722db0-6378-46b9-9849-560433611c6e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=4383069866440089#setting/sparkui/0327-152827-w3dc4eag/driver-3450497507746680894\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.1.2</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[8]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=4383069866440089#setting/sparkui/0327-152827-w3dc4eag/driver-3450497507746680894\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.1.2</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[8]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "]}}],"execution_count":0},{"cell_type":"markdown","source":["The example from the beginning of this lesson used the SparkSession method `table` to create a DataFrame from the `products` table. Let's save this in the variable `productsDF`."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cf05104f-75a5-4098-9acb-1b928d8a3dea"}}},{"cell_type":"code","source":["productsDF = spark.table(\"products\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8eae68a9-8d26-486a-8f94-dc7c3921ac6e"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Below are several additional methods we can use to create DataFrames. All of these can be found in the <a href=\"https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.SparkSession.html\" target=\"_blank\">documentation</a> for `SparkSession`.\n\n#### `SparkSession` Methods\n| Method | Description |\n| --- | --- |\n| sql | Returns a DataFrame representing the result of the given query | \n| table | Returns the specified table as a DataFrame |\n| read | Returns a DataFrameReader that can be used to read data in as a DataFrame |\n| range | Create a DataFrame with a column containing elements in a range from start to end (exclusive) with step value and number of partitions |\n| createDataFrame | Creates a DataFrame from a list of tuples, primarily used for testing |"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d98a97ab-9603-479d-9f79-acdc3bdf90f4"}}},{"cell_type":"markdown","source":["Let's use a SparkSession method to run SQL."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7e4122b8-372b-43e9-bc0c-5ae7478c34cd"}}},{"cell_type":"code","source":["resultDF = spark.sql(\"\"\"\nSELECT name, price\nFROM products\nWHERE price < 200\nORDER BY price\n\"\"\")\n\ndisplay(resultDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7a70199d-9442-4436-83cf-0b7ad69bec72"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["Standard Foam Pillow",59.0],["King Foam Pillow",79.0],["Standard Down Pillow",119.0],["King Down Pillow",159.0]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":[],"pivotAggregation":null,"xColumns":[],"yColumns":[]},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"name","type":"\"string\"","metadata":"{}"},{"name":"price","type":"\"double\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>name</th><th>price</th></tr></thead><tbody><tr><td>Standard Foam Pillow</td><td>59.0</td></tr><tr><td>King Foam Pillow</td><td>79.0</td></tr><tr><td>Standard Down Pillow</td><td>119.0</td></tr><tr><td>King Down Pillow</td><td>159.0</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## DataFrames\nRecall that expressing our query using methods in the DataFrame API returns results in a DataFrame. Let's store this in the variable `budgetDF`.\n\nA **DataFrame** is a distributed collection of data grouped into named columns."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"611e77a4-bb5a-48c2-ba54-a17842f3f76d"}}},{"cell_type":"code","source":["budgetDF = (spark.table(\"products\")\n  .select(\"name\", \"price\")\n  .where(\"price < 200\")\n  .orderBy(\"price\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"caaf49b5-9e32-46ca-b0cc-aa81b9059957"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["We can use `display()` to output the results of a dataframe."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e659f9c0-b061-4d0b-bdf7-c8b61fe534e9"}}},{"cell_type":"code","source":["display(budgetDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ea5a3237-dc51-4dd1-9347-03c030bea27d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["Standard Foam Pillow",59.0],["King Foam Pillow",79.0],["Standard Down Pillow",119.0],["King Down Pillow",159.0]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":[],"pivotAggregation":null,"xColumns":[],"yColumns":[]},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"name","type":"\"string\"","metadata":"{}"},{"name":"price","type":"\"double\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>name</th><th>price</th></tr></thead><tbody><tr><td>Standard Foam Pillow</td><td>59.0</td></tr><tr><td>King Foam Pillow</td><td>79.0</td></tr><tr><td>Standard Down Pillow</td><td>119.0</td></tr><tr><td>King Down Pillow</td><td>159.0</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["The **schema** defines the column names and types of a dataframe.\n\nAccess a dataframe's schema using the `schema` attribute."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"061b4bc9-297c-42d6-8187-def3869d4837"}}},{"cell_type":"code","source":["budgetDF.schema"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2fd647cd-e198-4dad-8281-edbc174e9fb1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[11]: StructType(List(StructField(name,StringType,true),StructField(price,DoubleType,true)))","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[11]: StructType(List(StructField(name,StringType,true),StructField(price,DoubleType,true)))"]}}],"execution_count":0},{"cell_type":"markdown","source":["View a nicer output for this schema using the `printSchema()` method."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dacffadc-d366-4223-96f2-110cee0bb3bd"}}},{"cell_type":"code","source":["budgetDF.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"325850e5-039d-4d8f-955f-bc69737c4ac0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- name: string (nullable = true)\n |-- price: double (nullable = true)\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- name: string (nullable = true)\n |-- price: double (nullable = true)\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Transformations\nWhen we created `budgetDF`, we used a series of DataFrame transformation methods e.g. `select`, `where`, `orderBy`. \n\n```\nproductsDF\n  .select(\"name\", \"price\")\n  .where(\"price < 200\")\n  .orderBy(\"price\")\n```\nTransformations operate on and return DataFrames, allowing us to chain transformation methods together to construct new DataFrames.  \nHowever, these operations can't execute on their own, as transformation methods are **lazily evaluated**. \n\nRunning the following cell does not trigger any computation."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d338a08f-3c57-4f8b-9961-af785018b2bb"}}},{"cell_type":"code","source":["(productsDF\n  .select(\"name\", \"price\")\n  .where(\"price < 200\")\n  .orderBy(\"price\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"80461fb1-1d35-4a86-870c-bd004eb9d5c4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[13]: DataFrame[name: string, price: double]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[13]: DataFrame[name: string, price: double]"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Actions\nConversely, DataFrame actions are methods that **trigger computation**.  \nActions are needed to trigger the execution of any DataFrame transformations. \n\nThe `show` action causes the following cell to execute transformations."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f273ff4a-ad23-4d14-b84f-78f7e36bc3d2"}}},{"cell_type":"code","source":["(productsDF\n  .select(\"name\", \"price\")\n  .where(\"price < 200\")\n  .orderBy(\"price\")\n  .show())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"441fa6a3-9f91-4ef1-a374-3858fd6d8558"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+--------------------+-----+\n|                name|price|\n+--------------------+-----+\n|Standard Foam Pillow| 59.0|\n|    King Foam Pillow| 79.0|\n|Standard Down Pillow|119.0|\n|    King Down Pillow|159.0|\n+--------------------+-----+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+--------------------+-----+\n|                name|price|\n+--------------------+-----+\n|Standard Foam Pillow| 59.0|\n|    King Foam Pillow| 79.0|\n|Standard Down Pillow|119.0|\n|    King Down Pillow|159.0|\n+--------------------+-----+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["Below are several examples of <a href=\"https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html#dataframe-apis\" target=\"_blank\">DataFrame</a> actions.\n\n### DataFrame Action Methods\n| Method | Description |\n| --- | --- |\n| show | Displays the top n rows of DataFrame in a tabular form |\n| count | Returns the number of rows in the DataFrame |\n| describe,  summary | Computes basic statistics for numeric and string columns |\n| first, head | Returns the the first row |\n| collect | Returns an array that contains all rows in this DataFrame |\n| take | Returns an array of the first n rows in the DataFrame |"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7f73bc0c-37c3-481e-94da-bfe9b193614c"}}},{"cell_type":"markdown","source":["`count` returns the number of records in a DataFrame."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"268f42d7-feac-4cb1-8b54-03beb37e9d3b"}}},{"cell_type":"code","source":["budgetDF.count()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3db86916-1171-46e5-bb51-5674d34597e7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[15]: 4","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[15]: 4"]}}],"execution_count":0},{"cell_type":"markdown","source":["`collect` returns an array of all rows in a DataFrame."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e2a97cfb-b046-4e1b-8eaa-2a6f816c4b87"}}},{"cell_type":"code","source":["budgetDF.collect() "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7b46e0d2-d8a7-4100-9a54-30b665b8b832"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[16]: [Row(name='Standard Foam Pillow', price=59.0),\n Row(name='King Foam Pillow', price=79.0),\n Row(name='Standard Down Pillow', price=119.0),\n Row(name='King Down Pillow', price=159.0)]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[16]: [Row(name='Standard Foam Pillow', price=59.0),\n Row(name='King Foam Pillow', price=79.0),\n Row(name='Standard Down Pillow', price=119.0),\n Row(name='King Down Pillow', price=159.0)]"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Convert between DataFrames and SQL"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a09ba136-1d0d-4a1f-b143-e92ff743771f"}}},{"cell_type":"markdown","source":["`createOrReplaceTempView` creates a temporary view based on the DataFrame. The lifetime of the temporary view is tied to the SparkSession that was used to create the DataFrame."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d4f96d5a-7088-4771-b172-25e84b43420b"}}},{"cell_type":"code","source":["budgetDF.createOrReplaceTempView(\"budget\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9d1ac1f7-d527-4dce-a2cc-0640196ef21a"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["display(spark.sql(\"SELECT * FROM budget\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a59326e6-e27d-46db-9612-7fab838d79ff"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["Standard Foam Pillow",59.0],["King Foam Pillow",79.0],["Standard Down Pillow",119.0],["King Down Pillow",159.0]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":[],"pivotAggregation":null,"xColumns":[],"yColumns":[]},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"name","type":"\"string\"","metadata":"{}"},{"name":"price","type":"\"double\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>name</th><th>price</th></tr></thead><tbody><tr><td>Standard Foam Pillow</td><td>59.0</td></tr><tr><td>King Foam Pillow</td><td>79.0</td></tr><tr><td>Standard Down Pillow</td><td>119.0</td></tr><tr><td>King Down Pillow</td><td>159.0</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# Spark SQL Lab\n\n##### Tasks\n1. Create a DataFrame from the `events` table\n1. Display the DataFrame and inspect its schema\n1. Apply transformations to filter and sort `macOS` events\n1. Count results and take the first 5 rows\n1. Create the same DataFrame using a SQL query\n\n##### Methods\n- <a href=\"https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.SparkSession.html?highlight=sparksession\" target=\"_blank\">SparkSession</a>: `sql`, `table`\n- <a href=\"https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.html\" target=\"_blank\">DataFrame</a> transformations: `select`, `where`, `orderBy`\n- <a href=\"https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.html\" target=\"_blank\">DataFrame</a> actions: `select`, `count`, `take`\n- Other <a href=\"https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.html\" target=\"_blank\">DataFrame</a> methods: `printSchema`, `schema`, `createOrReplaceTempView`"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"55c722ce-9613-4214-b727-8fa04bf10667"}}},{"cell_type":"markdown","source":["### 1. Create a DataFrame from the `events` table\n- Use SparkSession to create a DataFrame from the `events` table"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"51b97c6a-b946-474c-b641-6318b4dd86bf"}}},{"cell_type":"code","source":["# TODO\neventsDF = FILL_IN"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4965b30a-5a62-468b-a4ba-7b5c5e545cf4"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### 2. Display DataFrame and inspect schema\n- Use methods above to inspect DataFrame contents and schema"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1e0891ab-17dd-443e-8251-ff2068381243"}}},{"cell_type":"code","source":["# TODO"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1f203288-7ba5-4667-b67d-3e62521fce98"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### 3. Apply transformations to filter and sort `macOS` events\n- Filter for rows where `device` is `macOS`\n- Sort rows by `event_timestamp`\n\n<img src=\"https://files.training.databricks.com/images/icon_hint_32.png\" alt=\"Hint\"> Use single and double quotes in your filter SQL expression"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"06c993ef-0d0b-474f-a12d-56cf8297e90c"}}},{"cell_type":"code","source":["# TODO\nmacDF = (eventsDF\n         .FILL_IN\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c77a4904-292b-4ebd-a2de-d9175c222655"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)\n\u001B[0;32m<command-3252360928642504>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# TODO\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m macDF = (eventsDF\n\u001B[0m\u001B[1;32m      3\u001B[0m          \u001B[0;34m.\u001B[0m\u001B[0mFILL_IN\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m )\n\n\u001B[0;31mAttributeError\u001B[0m: type object 'FILL_IN' has no attribute 'FILL_IN'","errorSummary":"<span class='ansi-red-fg'>AttributeError</span>: type object 'FILL_IN' has no attribute 'FILL_IN'","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)\n\u001B[0;32m<command-3252360928642504>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# TODO\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m macDF = (eventsDF\n\u001B[0m\u001B[1;32m      3\u001B[0m          \u001B[0;34m.\u001B[0m\u001B[0mFILL_IN\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m )\n\n\u001B[0;31mAttributeError\u001B[0m: type object 'FILL_IN' has no attribute 'FILL_IN'"]}}],"execution_count":0},{"cell_type":"markdown","source":["### 4. Count results and take first 5 rows\n- Use DataFrame actions to count and take rows"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b68a44a5-53b0-4fc2-b202-ef6e3d0c50a1"}}},{"cell_type":"code","source":["# TODO\nnumRows = macDF.FILL_IN\nrows = macDF.FILL_IN"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8d4ba93e-1caa-4055-941e-91b1e6ca9847"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["**CHECK YOUR WORK**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fb2e57af-a4ea-4eb9-8726-58b22d9204e2"}}},{"cell_type":"code","source":["from pyspark.sql import Row\n\nassert(numRows == 1938215)\nassert(len(rows) == 5)\nassert(type(rows[0]) == Row)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2c2ae39e-3bf4-4491-bc19-00161ceb2248"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["### 5. Create the same DataFrame using SQL query\n- Use SparkSession to run a SQL query on the `events` table\n- Use SQL commands to write the same filter and sort query used earlier"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"86ea54e3-40f5-4511-86ae-3404266ef584"}}},{"cell_type":"code","source":["# TODO\nmacSQLDF = spark.FILL_IN\n\ndisplay(macSQLDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"588ff533-dd5d-4ed6-bb40-972b21859d07"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["**CHECK YOUR WORK**\n- You should only see `macOS` values in the `device` column\n- The fifth row should be an event with timestamp `1592539226602157`"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"944439af-82fe-4fe3-9627-a4226d3c2a38"}}},{"cell_type":"code","source":["verify_rows = macSQLDF.take(5)\nassert (macSQLDF.select(\"device\").distinct().count() == 1 and len(verify_rows) == 5 and verify_rows[0]['device'] == \"macOS\"), \"Incorrect filter condition\"\nassert (verify_rows[4]['event_timestamp'] == 1592539226602157), \"Incorrect sorting\"\ndel verify_rows"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"322ecd3c-1fcc-4cdf-9c44-9ecd52fc20d2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["### Classroom Cleanup"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"192d79bf-e6e7-49e8-a835-104e519dbdf3"}}},{"cell_type":"code","source":["%run ./Includes/Classroom-Cleanup"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6382e99d-9af8-40b8-9aad-bfc1223e12c0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"The execution of this command did not finish successfully","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\n&copy; 2022 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6858d26c-57f7-4abe-a5a8-bd81d7670c5b"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"ASP 1.3 - Spark SQL","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3252360928642458}},"nbformat":4,"nbformat_minor":0}
