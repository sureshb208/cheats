{"cells":[{"cell_type":"markdown","source":["-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c98f8d08-7950-4130-bc06-4bd6a66195ae"}}},{"cell_type":"markdown","source":["# Aggregating Streams\n\n##### Objectives\n1. Add watermarking\n1. Aggregate with windows\n1. Display streaming query results\n1. Monitor streaming queries\n\n##### Classes\n- <a href=\"https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.streaming.DataStreamReader.html#pyspark.sql.streaming.DataStreamReader\" target=\"_blank\">DataStreamReader</a>\n- <a href=\"https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.streaming.DataStreamWriter.html#pyspark.sql.streaming.DataStreamWriter\" target=\"_blank\">DataStreamWriter</a>\n- <a href=\"https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.streaming.StreamingQuery.html#pyspark.sql.streaming.StreamingQuery\" target=\"_blank\">StreamingQuery</a>\n- <a href=\"https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.streaming.StreamingQueryManager.html#pyspark.sql.streaming.StreamingQueryManager\" target=\"_blank\">StreamingQueryManager</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0dc598ee-a1f0-4222-b1a2-ca7ca2984a5a"}}},{"cell_type":"markdown","source":["## Hourly Activity by Traffic Lab\nProcess streaming data to display the total active users by traffic source with a 1 hour window.\n1. Cast to timestamp and add watermark for 2 hours\n2. Aggregate active users by traffic source for 1 hour windows\n3. Execute query with `display` and plot results\n5. Use query name to stop streaming query"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0dfec3e4-f681-4dae-bba1-1d6251d9fd65"}}},{"cell_type":"markdown","source":["### Setup\nRun the cells below to generate hourly JSON files of event data for July 3, 2020."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"073ce731-0e72-4dcb-8f4c-1bc070588984"}}},{"cell_type":"code","source":["%run ./Includes/Classroom-Setup"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1ed02a1b-5d63-4462-864d-2b7b65f0a36d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":[""]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Finished setting up utiltity methods...","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["Finished setting up utiltity methods..."]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Datasets mounted and student environment set up","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["Datasets mounted and student environment set up"]}}],"execution_count":0},{"cell_type":"code","source":["schema = \"device STRING, ecommerce STRUCT<purchase_revenue_in_usd: DOUBLE, total_item_quantity: BIGINT, unique_items: BIGINT>, event_name STRING, event_previous_timestamp BIGINT, event_timestamp BIGINT, geo STRUCT<city: STRING, state: STRING>, items ARRAY<STRUCT<coupon: STRING, item_id: STRING, item_name: STRING, item_revenue_in_usd: DOUBLE, price_in_usd: DOUBLE, quantity: BIGINT>>, traffic_source STRING, user_first_touch_timestamp BIGINT, user_id STRING\"\n\n# Directory of hourly events logged from the BedBricks website on July 3, 2020\nhourlyEventsPath = \"/mnt/training/ecommerce/events/events-2020-07-03.json\"\n\ndf = (spark\n      .readStream\n      .schema(schema)\n      .option(\"maxFilesPerTrigger\", 1)\n      .json(hourlyEventsPath)\n     )"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d77685c3-a856-43b9-b58e-2f7d69f07b05"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### 1. Cast to timestamp and add watermark for 2 hours\n- Add a **`createdAt`** column by dividing **`event_timestamp`** by 1M and casting to timestamp\n- Set a watermark of 2 hours on the **`createdAt`** column\n\nAssign the resulting DataFrame to **`eventsDF`**."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b23f1019-d508-47dc-92c9-02998e877449"}}},{"cell_type":"code","source":["# TODO\neventsDF = (df.FILL_IN\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4700b207-6b4c-4db9-a1d9-23372244f82f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)\n\u001B[0;32m<command-3252360928643669>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# TODO\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m eventsDF = (df.FILL_IN\n\u001B[0m\u001B[1;32m      3\u001B[0m )\n\n\u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py\u001B[0m in \u001B[0;36m__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   1664\u001B[0m         \"\"\"\n\u001B[1;32m   1665\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1666\u001B[0;31m             raise AttributeError(\n\u001B[0m\u001B[1;32m   1667\u001B[0m                 \"'%s' object has no attribute '%s'\" % (self.__class__.__name__, name))\n\u001B[1;32m   1668\u001B[0m         \u001B[0mjc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;31mAttributeError\u001B[0m: 'DataFrame' object has no attribute 'FILL_IN'","errorSummary":"<span class='ansi-red-fg'>AttributeError</span>: 'DataFrame' object has no attribute 'FILL_IN'","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)\n\u001B[0;32m<command-3252360928643669>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# TODO\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m eventsDF = (df.FILL_IN\n\u001B[0m\u001B[1;32m      3\u001B[0m )\n\n\u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py\u001B[0m in \u001B[0;36m__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   1664\u001B[0m         \"\"\"\n\u001B[1;32m   1665\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1666\u001B[0;31m             raise AttributeError(\n\u001B[0m\u001B[1;32m   1667\u001B[0m                 \"'%s' object has no attribute '%s'\" % (self.__class__.__name__, name))\n\u001B[1;32m   1668\u001B[0m         \u001B[0mjc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;31mAttributeError\u001B[0m: 'DataFrame' object has no attribute 'FILL_IN'"]}}],"execution_count":0},{"cell_type":"markdown","source":["**CHECK YOUR WORK**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"05aae63b-61ec-4ed4-8b49-de5f946e1de4"}}},{"cell_type":"code","source":["assert \"StructField(createdAt,TimestampType,true\" in str(eventsDF.schema)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"50fcfa49-e6cd-4a8c-9fea-215d63fb57bf"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["### 2. Aggregate active users by traffic source for 1 hour windows\n- Set the default shuffle partitions to the number of cores on your cluster (not required, but runs faster)\n- Group by **`traffic_source`** with 1-hour tumbling windows based on the **`createdAt`** column\n- Aggregate the approximate count of distinct users per **`traffic_source`** and hour, and alias the column to \"active_users\"\n- Select **`traffic_source`**, **`active_users`**, and the **`hour`** extracted from **`window.start`** with an alias of \"hour\"\n- Sort by **`hour`** in ascending order\n\nAssign the resulting DataFrame to **`trafficDF`**."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8d656696-9cac-4900-8953-90f74f230bdb"}}},{"cell_type":"code","source":["# TODO\nspark.FILL_IN\n\ntrafficDF = (eventsDF.FILL_IN\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0817fee8-e0d4-495e-a185-1ef2931163c5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["**CHECK YOUR WORK**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"af118ee2-eace-4467-803d-bd555c7117dd"}}},{"cell_type":"code","source":["assert str(trafficDF.schema) == \"StructType(List(StructField(traffic_source,StringType,true),StructField(active_users,LongType,false),StructField(hour,IntegerType,true)))\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ffad58cb-4b54-45d1-8a2e-09026a6362ea"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["### 3. Execute query with display() and plot results\n- Use `display` to start **`trafficDF`** as a streaming query and display the resulting memory sink\n  - Assign \"hourly_traffic\" as the name of the query by seting the **`streamName`** parameter of `display`\n- Plot the streaming query results as a bar graph\n- Configure the following plot options:\n  - Keys: **`hour`**\n  - Series groupings: **`traffic_source`**\n  - Values: **`active_users`**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"55a439b1-c6d4-4940-8e7d-51f19f84dc52"}}},{"cell_type":"code","source":["# TODO"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c1d6fb48-95f0-4d5f-99fc-a41661020d71"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["**CHECK YOUR WORK**\n\n- The bar chart should plot `hour` on the x-axis and `active_users` on the y-axis\n- Six bars should appear at every hour for all traffic sources\n- The chart should stop at hour 23"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"44a4c780-b8f8-414f-a9c7-6a4d059a3195"}}},{"cell_type":"markdown","source":["### 4. Manage streaming query\n- Iterate over SparkSession's list of active streams to find one with name \"hourly_traffic\"\n- Stop the streaming query"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"49acbb24-01d4-4e89-813b-e26bc6df11f3"}}},{"cell_type":"code","source":["# TODO\nuntilStreamIsReady(\"hourly_traffic\")\n\nfor s in FILL_IN:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"31ccd387-ff08-4ace-9cc2-3336be410d90"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["%md **CHECK YOUR WORK**  \nPrint all active streams to check that \"hourly_traffic\" is no longer there"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3b198302-2734-4d09-8de2-640040f11a33"}}},{"cell_type":"code","source":["for s in spark.streams.active:\n    print(s.name)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"54f753db-7601-4d7f-a687-19e95617ea63"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["### Classroom Cleanup\nRun the cell below to clean up resources."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6292fd51-e6f6-4cbe-8f6e-e1010d70c42a"}}},{"cell_type":"code","source":["%run ./Includes/Classroom-Cleanup"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2b028498-bf8f-4764-9966-3cfda573c4d0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"The execution of this command did not finish successfully","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\n&copy; 2022 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"33331f79-1663-4f2a-a6aa-8f0a667fd1a5"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"ASP 4.2 - Aggregating Streams","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3252360928643661}},"nbformat":4,"nbformat_minor":0}
